FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

LABEL github="https://github.com/mlcommons/GaNDLF"
LABEL docs="https://mlcommons.github.io/GaNDLF/"
LABEL version=1.0

# Install instructions for NVIDIA Container Toolkit allowing you to use the host's GPU: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
# Note that to do this on a Windows host you need experimental feature "CUDA on WSL" -- not yet stable.
ENV DEBIAN_FRONTEND=noninteractive
ARG BUILD_TYPE=cuda118

# Install jq early to parse JSON
RUN apt-get update && apt-get install -y jq

# Copy and read versions file
COPY versions.json /tmp/versions.json

# Display versions being used
RUN echo "=== Building ${BUILD_TYPE} version with the following versions ===" && \
    cat /tmp/versions.json && \
    echo "==========================================="

# Explicitly install python3.11
RUN apt-get install -y software-properties-common git

# Install Python using version from JSON
RUN PYTHON_VERSION=$(jq -r '.python' /tmp/versions.json) && \
    echo "Installing Python ${PYTHON_VERSION}" && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt install -y python${PYTHON_VERSION} \
                   libpython${PYTHON_VERSION}-dev \
                   libpython${PYTHON_VERSION} \
                   python${PYTHON_VERSION}-venv \
                   python3-pip

# Install additional dependencies
RUN apt-get install -y libjpeg8-dev zlib1g-dev libffi-dev libgl1

# Fix pip version because of weird PyYAML issue
RUN python3.11 -m pip install --upgrade pip
RUN python3.11 -m pip install uv

# Install PyTorch packages with CUDA 11.8 support using versions from JSON
RUN PYTORCH_VERSION=$(jq -r '.pytorch.version' /tmp/versions.json) && \
    TORCHVISION_VERSION=$(jq -r '.pytorch.torchvision' /tmp/versions.json) && \
    TORCHAUDIO_VERSION=$(jq -r '.pytorch.torchaudio' /tmp/versions.json) && \
    PYTORCH_INDEX=$(jq -r '.pytorch.index.cuda118' /tmp/versions.json) && \
    echo "Installing PyTorch ${PYTORCH_VERSION} (${PYTORCH_INDEX}), TorchVision ${TORCHVISION_VERSION}, TorchAudio ${TORCHAUDIO_VERSION}" && \
    uv pip install torch==${PYTORCH_VERSION} \
                   torchvision==${TORCHVISION_VERSION} \
                   torchaudio==${TORCHAUDIO_VERSION} \
                   --index-url https://download.pytorch.org/whl/${PYTORCH_INDEX} --system

RUN uv pip install openvino-dev opencv-python-headless --system

# Do some dependency installation separately here to make layer caching more efficient
COPY ./setup.py ./setup.py
RUN python3.11 -c "from setup import requirements; file = open('requirements.txt', 'w'); file.writelines([req + '\n' for req in requirements]); file.close()" \
  && uv pip install -r ./requirements.txt --system

COPY . /GaNDLF
WORKDIR /GaNDLF
RUN uv pip install -e . --system

# Entrypoint forces all commands given via "docker run" to go through python, CMD forces the default entrypoint script argument to be gandlf run
# If a user calls "docker run gandlf:[tag] anonymize", it will resolve to running "gandlf anonymize" instead.
# CMD is inherently overridden by args to "docker run", entrypoint is constant.
ENTRYPOINT gandlf
CMD run

# The below force the container commands to run as a nonroot user with UID > 10000.
# This greatly reduces UID collision probability between container and host, helping prevent privilege escalation attacks.
# As a side benefit this also decreases the likelihood that users on a cluster won't be able to access their files.
# See https://github.com/hexops/dockerfile as a best practices guide.
#RUN addgroup --gid 10001 --system nonroot \
# && adduser --uid 10000 --system --ingroup nonroot --home /home/nonroot nonroot

#USER nonroot

# Prepare the container for possible model embedding later.
RUN mkdir /embedded_model